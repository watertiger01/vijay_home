{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd2c693-8f3d-44be-acdf-f6655407ecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thema\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'span', 'label', 'ordinal'],\n",
      "        num_rows: 2358\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'span', 'label', 'ordinal'],\n",
      "        num_rows: 654\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"tomaarsen/setfit-absa-semeval-laptops\")\n",
    "\n",
    "# Print dataset information\n",
    "print(dataset)\n",
    "import pandas as pd\n",
    "\n",
    "# Convert train split to a pandas DataFrame\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "\n",
    "# Save train DataFrame to CSV\n",
    "train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "\n",
    "# Convert test split to a pandas DataFrame\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# Save test DataFrame to CSV\n",
    "test_df.to_csv(\"test_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3750e713-3f32-41be-adfb-acf40145adbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>cord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I charge it at night and skip taking the cord ...</td>\n",
       "      <td>battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>service center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>\"sales\" team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech guy then said the service center does...</td>\n",
       "      <td>tech guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server Enterprise 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "      <td>We also use Paralles so we can run virtual mac...</td>\n",
       "      <td>Windows Server 2008 Enterprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>How Toshiba handles the repair seems to vary, ...</td>\n",
       "      <td>repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>How Toshiba handles the repair seems to vary, ...</td>\n",
       "      <td>repair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>I would like to use a different operating syst...</td>\n",
       "      <td>operating system</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2358 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0     I charge it at night and skip taking the cord ...   \n",
       "1     I charge it at night and skip taking the cord ...   \n",
       "2     The tech guy then said the service center does...   \n",
       "3     The tech guy then said the service center does...   \n",
       "4     The tech guy then said the service center does...   \n",
       "...                                                 ...   \n",
       "2353  We also use Paralles so we can run virtual mac...   \n",
       "2354  We also use Paralles so we can run virtual mac...   \n",
       "2355  How Toshiba handles the repair seems to vary, ...   \n",
       "2356  How Toshiba handles the repair seems to vary, ...   \n",
       "2357  I would like to use a different operating syst...   \n",
       "\n",
       "                                span  \n",
       "0                               cord  \n",
       "1                       battery life  \n",
       "2                     service center  \n",
       "3                       \"sales\" team  \n",
       "4                           tech guy  \n",
       "...                              ...  \n",
       "2353  Windows Server Enterprise 2003  \n",
       "2354  Windows Server 2008 Enterprise  \n",
       "2355                          repair  \n",
       "2356                          repair  \n",
       "2357                operating system  \n",
       "\n",
       "[2358 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['text','span']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b0f6fc7-98db-457c-b1c2-8baee0092458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.2983441716096422\n",
      "Epoch 2, Loss: 0.004164424565715308\n",
      "Epoch 3, Loss: 0.002472554174346442\n",
      "Test Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tokenize text using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "class AspectDataset(Dataset):\n",
    "    def __init__(self, data, max_length=128):  # Set max_length to desired value\n",
    "        self.data = data\n",
    "        self.tokenized_texts = []\n",
    "        self.labels = []\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        for idx, row in self.data.iterrows():\n",
    "            text = row['text']\n",
    "            spans = [asp.strip() for asp in row['span'].split(\"|\")]\n",
    "            tokenized_text = tokenizer.encode(text, add_special_tokens=True, max_length=self.max_length, padding='max_length', truncation=True)\n",
    "            self.tokenized_texts.append(tokenized_text)\n",
    "            label = [1 if tokenizer.decode(tokenized_text[i]) in spans else 0 for i in range(len(tokenized_text))]\n",
    "            self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.tokenized_texts[idx]),\n",
    "            'labels': torch.tensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "train_dataset = AspectDataset(train_df)\n",
    "test_dataset = AspectDataset(test_df)\n",
    "\n",
    "# Define the model\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "        loss = criterion(logits.view(-1, 2), labels.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "        predicted_labels = torch.argmax(logits, dim=2)\n",
    "        total_correct += torch.sum(predicted_labels == labels).item()\n",
    "        total_samples += labels.numel()\n",
    "\n",
    "accuracy = total_correct / total_samples\n",
    "print(f\"Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eef52de4-c250-4e53-9593-247eb2d6d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Aspect Terms: []\n"
     ]
    }
   ],
   "source": [
    "def predict_aspect_terms(model, tokenizer, text, device):\n",
    "    tokenized_text = tokenizer.encode(text, add_special_tokens=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokenized_text)\n",
    "    logits = outputs.logits\n",
    "    predicted_labels = torch.argmax(logits, dim=2).squeeze().tolist()\n",
    "    predicted_tokens = [tokenizer.decode(tokenized_text[0, i].item()) for i, label in enumerate(predicted_labels) if label == 1]\n",
    "    return predicted_tokens\n",
    "\n",
    "# Example usage\n",
    "input_text = \"I charge it at night and skip taking the cord with me because of the good battery life.\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "predicted_aspect_terms = predict_aspect_terms(model, tokenizer, input_text, device)\n",
    "print(\"Predicted Aspect Terms:\", predicted_aspect_terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cfb60408-97e0-493b-ac12-6d052289e28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I charge it at night and skip taking the cord with me because of the good battery life.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e773e8-aeb1-417e-8cac-4ddf6729e6f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_env",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
